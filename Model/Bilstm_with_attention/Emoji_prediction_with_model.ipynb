{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from rnn_model.attention_lstm import bilstm_with_attention\n",
    "from tensorflow.contrib import rnn\n",
    "import pickle\n",
    "import konlpy\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict','rb') as fp:\n",
    "    word_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'ÏùºÎã® ÎÑàÌïúÌÖå ÎßéÏù¥ ÎØ∏ÏïàÌï¥ ÎÇ¥Í∞Ä Ïù¥Í∏∞Ï†ÅÏù¥ÎùºÏÑú Í∞§ ÏûäÏùÑ Ïàò ÏûàÍ≤å ÎèÑÏôÄÏ§ò. ÏõêÌïòÏßÄ ÏïäÍ≤å ÎßûÏù¥ÌñàÎçò Ïù¥Î≥ÑÏù¥ÎùºÏÑú ÎÇ† Ïïà ÎÜìÏïÑÏ§ò'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = [tokenize(a)]\n",
    "tokens = list(map(lambda d: list(map(lambda w: word_dict.get(w, word_dict[\"<unk>\"]), d)), input_sentence))\n",
    "tokens = list(map(lambda d: d + [word_dict[\"<eos>\"]], tokens))\n",
    "tokens = list(map(lambda d: d + (80 - len(d)) * [word_dict[\"<pad>\"]], tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[494,\n",
       "  151,\n",
       "  181,\n",
       "  69,\n",
       "  1,\n",
       "  46,\n",
       "  6,\n",
       "  103,\n",
       "  2572,\n",
       "  1531,\n",
       "  864,\n",
       "  708,\n",
       "  64,\n",
       "  9,\n",
       "  1833,\n",
       "  1,\n",
       "  904,\n",
       "  66,\n",
       "  3844,\n",
       "  3,\n",
       "  4672,\n",
       "  1531,\n",
       "  144,\n",
       "  18,\n",
       "  356,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from BILSTM_attention/BILSTM_attention.ckpt-35125\n"
     ]
    }
   ],
   "source": [
    "num_class=30\n",
    "embedding_size = 256\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1\n",
    "WORD_MAX_LEN = 80\n",
    "vocabulary_size = len(word_dict)\n",
    "from tensorflow.contrib import rnn\n",
    "       \n",
    "      \n",
    "num_class=30\n",
    "embedding_size = 256\n",
    "num_hidden = 256\n",
    "num_layers = 2\n",
    "learning_rate = 1e-3\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.int32, [None, 80], name=\"x\")\n",
    "x_len = tf.reduce_sum(tf.sign(x), 1)\n",
    "y = tf.placeholder(tf.int32, [None], name=\"y\")\n",
    "is_training = tf.placeholder(tf.bool, [], name=\"is_training\")\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "keep_prob = tf.where(is_training, 0.5, 1.0)\n",
    "\n",
    "with tf.name_scope(\"embedding\"):\n",
    "    init_embeddings = tf.random_uniform([vocabulary_size, embedding_size])\n",
    "    embeddings = tf.get_variable(\"embeddings\", initializer=init_embeddings)\n",
    "    x_emb = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "with tf.name_scope(\"birnn\"):\n",
    "    fw_cells = [rnn.BasicLSTMCell(num_hidden) for _ in range(num_layers)]\n",
    "    bw_cells = [rnn.BasicLSTMCell(num_hidden) for _ in range(num_layers)]\n",
    "    fw_cells = [rnn.DropoutWrapper(cell, output_keep_prob=keep_prob) for cell in fw_cells]\n",
    "    bw_cells = [rnn.DropoutWrapper(cell, output_keep_prob=keep_prob) for cell in bw_cells]\n",
    "\n",
    "rnn_outputs, _, _ = rnn.stack_bidirectional_dynamic_rnn(\n",
    "fw_cells, bw_cells, x_emb, sequence_length=x_len, dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope(\"attention\"):\n",
    "    attention_score = tf.nn.softmax(tf.layers.dense(rnn_outputs, 1, activation=tf.nn.tanh), axis=1)\n",
    "    attention_out = tf.squeeze(\n",
    "    tf.matmul(tf.transpose(rnn_outputs, perm=[0, 2, 1]), attention_score),axis=-1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(attention_out, num_class, activation=tf.nn.softmax)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "modelName = \"BILSTM_attention/BILSTM_attention.ckpt-35125\"\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "saver.restore(sess, modelName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = sess.run(tf.nn.top_k(logits,5,sorted=True), feed_dict = {x: np.array(tokens).reshape(1,80),is_training:False})\n",
    "\n",
    "attention_weights = sess.run(attention_score,feed_dict = {x: np.array(tokens).reshape(1,80),is_training:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 13, 24, 19, 10]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['üòî', 'üò¢', 'üòû', 'üôè', 'üòï']\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    if probabilities.indices[0][i] == 1:\n",
    "        a.append(u'\\U0001F44D')\n",
    "    elif probabilities.indices[0][i] == 13:\n",
    "        a.append(u'\\U0001F622')\n",
    "    elif probabilities.indices[0][i] == 0:\n",
    "        a.append(u'\\U0001F44C')\n",
    "    elif probabilities.indices[0][i] == 2:\n",
    "        a.append(u'\\U0001F601')\n",
    "    elif probabilities.indices[0][i] == 3:\n",
    "        a.append(u'\\U0001F602')\n",
    "    elif probabilities.indices[0][i] == 4:\n",
    "        a.append(u'\\U0001F608')\n",
    "    elif probabilities.indices[0][i] == 5:\n",
    "        a.append(u'\\U0001F60A')\n",
    "    elif probabilities.indices[0][i] == 6:\n",
    "        a.append(u'\\U0001F60D')\n",
    "    elif probabilities.indices[0][i] == 7:\n",
    "        a.append(u'\\U0001F60F')\n",
    "    elif probabilities.indices[0][i] == 8:\n",
    "        a.append(u'\\U0001F612')\n",
    "    elif probabilities.indices[0][i] == 9:\n",
    "        a.append(u'\\U0001F614')\n",
    "    elif probabilities.indices[0][i] == 10:\n",
    "        a.append(u'\\U0001F615')\n",
    "    elif probabilities.indices[0][i] == 11:\n",
    "        a.append(u'\\U0001F618')\n",
    "    elif probabilities.indices[0][i] == 12:\n",
    "        a.append(u'\\U0001F621')\n",
    "    elif probabilities.indices[0][i] == 14:\n",
    "        a.append(u'\\U0001F629')\n",
    "    elif probabilities.indices[0][i] == 15:\n",
    "        a.append(u'\\U0001F62D')\n",
    "    elif probabilities.indices[0][i] == 16:\n",
    "        a.append(u'\\U0001F633')\n",
    "    elif probabilities.indices[0][i] == 17:\n",
    "        a.append(u'\\U0001F635')\n",
    "    elif probabilities.indices[0][i] == 18:\n",
    "        a.append(u'\\U0001F637')\n",
    "    elif probabilities.indices[0][i] == 19:\n",
    "        a.append(u'\\U0001F64F')\n",
    "    elif probabilities.indices[0][i] == 20:\n",
    "        a.append(u'\\U0001F605')\n",
    "    elif probabilities.indices[0][i] == 21:\n",
    "        a.append(u'\\U0001F60B')\n",
    "    elif probabilities.indices[0][i] == 22:\n",
    "        a.append(u'\\U0001F60E')\n",
    "    elif probabilities.indices[0][i] == 23:\n",
    "        a.append(u'\\U0001F61C')\n",
    "    elif probabilities.indices[0][i] == 24:\n",
    "        a.append(u'\\U0001F61E')\n",
    "    elif probabilities.indices[0][i] == 25:\n",
    "        a.append(u'\\U0001F603')\n",
    "    elif probabilities.indices[0][i] == 26:\n",
    "        a.append(u'\\U0001F648')\n",
    "    elif probabilities.indices[0][i] == 27:\n",
    "        a.append(u'\\U0001F64C')\n",
    "    elif probabilities.indices[0][i] == 28:\n",
    "        a.append(u'\\U0001F914')\n",
    "    elif probabilities.indices[0][i] == 29:\n",
    "        a.append(u'\\U0001F611')\n",
    "        \n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = [a[0] for a in attention_weights[0]]\n",
    "enumerated_attention = list(enumerate(attention))\n",
    "index_sorted_attention= sorted(enumerated_attention, key=lambda x:x[1],reverse=True)\n",
    "top3_index = [x[0] for x in index_sorted_attention[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïïà/Noun\n",
      "ÎèÑÏôÄÏ£ºÎã§/Verb\n",
      "Ïàò/Noun\n",
      "ÏõêÌïòÎã§/Adjective\n",
      "Ïù¥Î≥Ñ/Noun\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(input_sentence[0][top3_index[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
